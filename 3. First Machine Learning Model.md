# **First Machine Learning Model**

## **Selecting Data for Modeling**

Your dataset had too many variables to wrap your head around, or even to print out nicely. How can you pare down this overwhelming amount of data to something you can understand?

We'll start by picking a few variables using our intuition. Later courses will show you statistical techniques to automatically prioritize variables.

To choose variables/columns, we'll need to see a list of all columns in the dataset. That is done with the columns property of the DataFrame (the bottom line of code below).

```python
import pandas as pd

melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
melbourne_data = pd.read_csv(melbourne_file_path) 
melbourne_data.columns
```

Output:
```
Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',
       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',
       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',
       'Longtitude', 'Regionname', 'Propertycount'],
      dtype='object')
```

The Melbourne data has some missing values (some houses for which some variables weren't recorded). We'll learn to handle missing values in a later tutorial. Your Iowa data doesn't have missing values in the columns you use. So we will take the simplest option for now, and drop houses from our data. Don't worry about this much for now, though the code is:

```python
# dropna drops missing values (think of na as "not available")
melbourne_data = melbourne_data.dropna(axis=0)
```

There are many ways to select a subset of your data. The Pandas course covers these in more depth, but we will focus on two approaches for now.

1. Dot notation, which we use to select the "prediction target"
2. Selecting with a column list, which we use to select the "features"

## **Selecting The Prediction Target**

You can pull out a variable with dot-notation. This single column is stored in a Series, which is broadly like a DataFrame with only a single column of data.

We'll use the dot notation to select the column we want to predict, which is called the prediction target. By convention, the prediction target is called y. So the code we need to save the house prices in the Melbourne data is:

```python
y = melbourne_data.Price
```

## **Choosing "Features"**

The columns that are inputted into our model (and later used to make predictions) are called "features." In our case, those would be the columns used to determine the home price. Sometimes, you will use all columns except the target as features. Other times you'll be better off with fewer features.

For now, we'll build a model with only a few features. Later on you'll see how to iterate and compare models built with different features.

We select multiple features by providing a list of column names inside brackets. Each item in that list should be a string (with quotes).

Here is an example:

```python
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']
```

By convention, this data is called X.

```python
X = melbourne_data[melbourne_features]
```

Let's quickly review the data we'll be using to predict house prices using the describe method and the head method, which shows the top few rows.

```python
X.describe()
```

Output:

![image](https://github.com/user-attachments/assets/ba74213b-1850-425f-9370-b6a316006fc3)


```python
X.head()
```

Output:

![image](https://github.com/user-attachments/assets/f5492a97-32d6-476e-b400-fb000bc108a2)


Visually checking your data with these commands is an important part of a data scientist's job. You'll frequently find surprises in the dataset that deserve further inspection.

## **Building Your Model**

You will use the scikit-learn library to create your models. When coding, this library is written as sklearn, as you will see in the sample code. Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.

The steps to building and using a model are:

1. **Define**: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.
2. **Fit**: Capture patterns from provided data. This is the heart of modeling.
3. **Predict**: Just what it sounds like
4. **Evaluate**: Determine how accurate the model's predictions are.

Here is an example of defining a decision tree model with scikit-learn and fitting it with the features and target variable.

```python
from sklearn.tree import DecisionTreeRegressor

# Define model. Specify a number for random_state to ensure same results each run
melbourne_model = DecisionTreeRegressor(random_state=1)

# Fit model
melbourne_model.fit(X, y)
```

Output:
```
DecisionTreeRegressor(random_state=1)
```

Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run. This is considered a good practice. You use any number, and model quality won't depend meaningfully on exactly what value you choose.

We now have a fitted model that we can use to make predictions.

In practice, you'll want to make predictions for new houses coming on the market rather than the houses we already have prices for. But we'll make predictions for the first few rows of the training data to see how the predict function works.

```python
print("Making predictions for the following 5 houses:")
print(X.head())
print("The predictions are")
print(melbourne_model.predict(X.head()))
```

Output:
```
Making predictions for the following 5 houses:
   Rooms  Bathroom  Landsize  Lattitude  Longtitude
1      2       1.0     156.0   -37.8079    144.9934
2      3       2.0     134.0   -37.8093    144.9944
4      4       1.0     120.0   -37.8072    144.9941
6      3       2.0     245.0   -37.8024    144.9993
7      2       1.0     256.0   -37.8060    144.9954
The predictions are
[1035000. 1465000. 1600000. 1876000. 1636000.]
```

## **Practice Exercise**

Now it's time to practice what you've learned by building your own machine learning model.

### **Task:**
1. Load the Iowa housing dataset
2. Select features and target variable
3. Build a decision tree model
4. Make predictions

### **Solution:**

```python
# Import libraries
import pandas as pd
from sklearn.tree import DecisionTreeRegressor

# Load the data
iowa_file_path = '../input/home-data-for-ml-course/train.csv'
iowa_data = pd.read_csv(iowa_file_path)

# View the list of columns
print("Available columns:")
print(iowa_data.columns)

# Choose target (y) and features (X)
y = iowa_data.SalePrice

# Choose features focused on house size
features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'TotalBsmtSF', 
            'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']

X = iowa_data[features]

# Review the data
print("\nFeatures summary statistics:")
print(X.describe())

print("\nFirst few rows of features:")
print(X.head())

# Define the model
iowa_model = DecisionTreeRegressor(random_state=1)

# Fit the model
iowa_model.fit(X, y)

# Make predictions on the first 5 houses
print("\nPredictions for the first 5 houses:")
print(iowa_model.predict(X.head()))

print("\nActual prices for the first 5 houses:")
print(y.head())
```

This practice exercise applies all the concepts you've learned to a different dataset, helping reinforce your understanding of the machine learning workflow.

### **Key Takeaways:**

1. The basic machine learning process follows these steps:
   - Select and prepare your data
   - Choose a model type
   - Train (fit) the model on your data
   - Use the model to make predictions

2. Decision trees are a good starting point for beginners because they're:
   - Easy to understand
   - Require minimal data preparation
   - Can handle both numerical and categorical features

3. Always remember to:
   - Check your data before modeling
   - Use random_state for reproducibility
   - Compare predictions with actual values to assess performance
